\relax 
\providecommand\hyper@newdestlabel[2]{}
\bibstyle{elsarticle-harv}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\emailauthor{rostami-tabarb@cardiff.ac.uk}{Bahman Rostami-tabar\corref {1}}
\emailauthor{DejanMircetic@uns.ac.rs}{Dejan Mircetic\corref {2}}
\Newlabel{1}{1}
\Newlabel{2}{2}
\Newlabel{Cardiff Business School}{a}
\Newlabel{University of Novi Sad Faculty of Technical Sciences}{b}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{introduction}{{1}{1}{Introduction}{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Aggregate forecast vs. aggregate data approaches. Assuming a montly time series is available and a forecast over one quarter (aggregation level = 3 months) is required. We first generate forecast for 3 periods ahead and then sum them up to create forecast over the quarter (Forecast by AF approach). Then, we create the temporally aggregated series by dividing the original series into the block of 3 periods. Next, we forecast for 1 period ahead (Forecast by AD approach).}}{2}{figure.1}}
\newlabel{fig:example_oanoa}{{1}{2}{Aggregate forecast vs. aggregate data approaches. Assuming a montly time series is available and a forecast over one quarter (aggregation level = 3 months) is required. We first generate forecast for 3 periods ahead and then sum them up to create forecast over the quarter (Forecast by AF approach). Then, we create the temporally aggregated series by dividing the original series into the block of 3 periods. Next, we forecast for 1 period ahead (Forecast by AD approach)}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Research background}{3}{section.2}}
\newlabel{lit}{{2}{3}{Research background}{section.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experiment framework}{5}{section.3}}
\newlabel{framework}{{3}{5}{Experiment framework}{section.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Design of the experiment framework}}{6}{figure.2}}
\newlabel{fig:expdes}{{2}{6}{Design of the experiment framework}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Forecasting approaches}{6}{subsection.3.1}}
\newlabel{forecasting-approaches}{{3.1}{6}{Forecasting approaches}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Forecasting method}{7}{subsection.3.2}}
\newlabel{forecasting-method}{{3.2}{7}{Forecasting method}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Forecast accuracy measures}{7}{subsection.3.3}}
\newlabel{errormetric}{{3.3}{7}{Forecast accuracy measures}{subsection.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Time series data, features and temporal aggregation performance}{8}{section.4}}
\newlabel{tsfeature}{{4}{8}{Time series data, features and temporal aggregation performance}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Time series features}{8}{subsection.4.1}}
\newlabel{time-series-features}{{4.1}{8}{Time series features}{subsection.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Time series features of monthly M4 data}{8}{subsection.4.2}}
\newlabel{mtsmeasure}{{4.2}{8}{Time series features of monthly M4 data}{subsection.4.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Time series features considered in this study and their descriptions}}{9}{table.1}}
\newlabel{tab:summaryfeature}{{1}{9}{Time series features considered in this study and their descriptions}{table.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Features of monthly time series from M4 competition dataset}}{10}{figure.3}}
\newlabel{fig:feature1}{{3}{10}{Features of monthly time series from M4 competition dataset}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Features of monthly time series from M4 competition dataset (continue)}}{11}{figure.4}}
\newlabel{fig:feature2}{{4}{11}{Features of monthly time series from M4 competition dataset (continue)}{figure.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Effect of temporal aggregation on time series features}{11}{subsection.4.3}}
\newlabel{taeffect}{{4.3}{11}{Effect of temporal aggregation on time series features}{subsection.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The effect of non-overlapping temporal aggregation on monthly time series features of M4 competition dataset}}{12}{figure.5}}
\newlabel{fig:featureagg1}{{5}{12}{The effect of non-overlapping temporal aggregation on monthly time series features of M4 competition dataset}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The effect of non-overlapping temporal aggregation on monthly time series features of M4 competition dataset (continue)}}{13}{figure.6}}
\newlabel{fig:featureagg2}{{6}{13}{The effect of non-overlapping temporal aggregation on monthly time series features of M4 competition dataset (continue)}{figure.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Forecast accuracy evaluation of AD and AF approaches}{13}{subsection.4.4}}
\newlabel{forecast-accuracy-evaluation-of-ad-and-af-approaches}{{4.4}{13}{Forecast accuracy evaluation of AD and AF approaches}{subsection.4.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces RMSSE errors through aggregation levels.}}{14}{figure.7}}
\newlabel{fig:RMSSE}{{7}{14}{RMSSE errors through aggregation levels}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Performance of BU and DA models evaluated through MCB test. RMSSE errors are used for computing the ranks and a 95 percentile confidence level.}}{14}{figure.8}}
\newlabel{fig:MCB}{{8}{14}{Performance of BU and DA models evaluated through MCB test. RMSSE errors are used for computing the ranks and a 95 percentile confidence level}{figure.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Machine learining models}{15}{section.5}}
\newlabel{ml}{{5}{15}{Machine learining models}{section.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Time series features matrix. Each point indicates one single time series with a feature in x-axis and another at y-axis. The black and yellow colors show the outperformance of AD and AF, respectively.}}{16}{figure.9}}
\newlabel{fig:featuresmatrix}{{9}{16}{Time series features matrix. Each point indicates one single time series with a feature in x-axis and another at y-axis. The black and yellow colors show the outperformance of AD and AF, respectively}{figure.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Evaluating the prediction accuracy fo ML models in classification}{16}{subsection.5.1}}
\newlabel{evaluating-the-prediction-accuracy-fo-ml-models-in-classification}{{5.1}{16}{Evaluating the prediction accuracy fo ML models in classification}{subsection.5.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Comparison of different ML models}}{17}{table.2}}
\newlabel{tab:cost}{{2}{17}{Comparison of different ML models}{table.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Performance of different models evaluated through MCB test. RMSSE errors are used for computing the ranks and a 95 percentile confidence level.}}{17}{figure.10}}
\newlabel{fig:MCB_ML}{{10}{17}{Performance of different models evaluated through MCB test. RMSSE errors are used for computing the ranks and a 95 percentile confidence level}{figure.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Cost and benefit matrix}}{18}{table.3}}
\newlabel{tab:matrix}{{3}{18}{Cost and benefit matrix}{table.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Utility accuracy comparison}}{18}{figure.11}}
\newlabel{fig:tableCB}{{11}{18}{Utility accuracy comparison}{figure.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Building the random forest algorithm}{18}{subsection.5.2}}
\newlabel{building-the-random-forest-algorithm}{{5.2}{18}{Building the random forest algorithm}{subsection.5.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Random Forest methodology.}}{19}{algorithm.1}}
\newlabel{alg:RF}{{1}{19}{Building the random forest algorithm}{Item.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Surface plot of the number of features (depth), number of trees and misclassification error of random forest model.}}{20}{figure.12}}
\newlabel{fig:surface}{{12}{20}{Surface plot of the number of features (depth), number of trees and misclassification error of random forest model}{figure.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Determining the optimal depth and the of number the trees in the random forest model.}}{21}{figure.13}}
\newlabel{fig:tree_depth}{{13}{21}{Determining the optimal depth and the of number the trees in the random forest model}{figure.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Association between time series feasutes and AF/AD performance}{21}{section.6}}
\newlabel{res}{{6}{21}{Association between time series feasutes and AF/AD performance}{section.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Predictor features importance spectrum for the M4 data. A feature importance is computed using the mean decrease in Gini index.}}{21}{figure.14}}
\newlabel{fig:RFpartial}{{14}{21}{Predictor features importance spectrum for the M4 data. A feature importance is computed using the mean decrease in Gini index}{figure.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Partial dependence plots}}{22}{figure.15}}
\newlabel{fig:pdpcommon1}{{15}{22}{Partial dependence plots}{figure.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Partial dependence plot (continue)}}{23}{figure.16}}
\newlabel{fig:pdpcommon2}{{16}{23}{Partial dependence plot (continue)}{figure.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions}{24}{section.7}}
\newlabel{con}{{7}{24}{Conclusions}{section.7}{}}
\newlabel{references}{{7}{26}{References}{section*.1}{}}
\@writefile{toc}{\contentsline {section}{References}{26}{section*.1}}
